{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "410aed18-dd0f-44c0-aa68-f2b8e7485789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CNNs_Project_App.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile  CNNs_Project_App.py\n",
    "import streamlit as st\n",
    "import joblib as jb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "st.set_page_config(page_icon='üçé', page_title='Fruits And Vegetables Model')\n",
    "tab1, tab2 = st.tabs(['Introduction', 'Models'])\n",
    "\n",
    "with tab1:\n",
    "    st.header('Introduction')\n",
    "    st.markdown('#### **In this project, three different CNN models were trained on approximately 29,000 images.**')\n",
    "    st.markdown('##### These images included 14 types of vegetables and fruits, divided into 28 categories.')\n",
    "    col1, col2, col3, col4 = st.columns([1, 1, 1, 1])\n",
    "    \n",
    "    for col, fruit, healthy_img, rotten_img in zip(\n",
    "        [col1, col2, col3, col4],\n",
    "        [\"Mango\", \"Apple\", \"Banana\", \"Potato\"],\n",
    "        [\"photo display/mango_helthy.jpg\", \"photo display/FreshApple (1).jpg\", \"photo display/Banana__Healthy_augmented_12.jpg\", \"photo display/freshPotato (1).jpeg\"],\n",
    "        [\"photo display/mango_rotten.jpeg\", \"photo display/apple_rotten.jpg\", \"photo display/banana_rotten.png\", \"photo display/potato_rotten.jpeg\"]\n",
    "    ):\n",
    "        col.write(fruit)\n",
    "        sub_col1, sub_col2 = col.columns([1, 1])\n",
    "        with sub_col1:\n",
    "            st.write('Healthy')\n",
    "            st.image(healthy_img)\n",
    "        with sub_col2:\n",
    "            st.write('Rotten')\n",
    "            st.image(rotten_img)\n",
    "    \n",
    "    col5, col6, col7 = st.columns([1, 1, 1])\n",
    "    \n",
    "    for col, fruit, healthy_img, rotten_img in zip(\n",
    "        [col5, col6, col7],\n",
    "        [\"Pepper\", \"Orange\", \"Tomato\"],\n",
    "        [\"photo display/freshPepper (1).jpeg\", \"photo display/freshOrange (1).jpg\", \"photo display/freshTomato (5).png\"],\n",
    "        [\"photo display/rottenPepper (140).jpg\", \"photo display/rottenOrange (77).jpg\", \"photo display/rottenTomato (57).jpg\"]\n",
    "    ):\n",
    "        col.write(fruit)\n",
    "        sub_col1, sub_col2 = col.columns([1, 1])\n",
    "        with sub_col1:\n",
    "            st.write('Healthy')\n",
    "            st.image(healthy_img)\n",
    "        with sub_col2:\n",
    "            st.write('Rotten')\n",
    "            st.image(rotten_img)\n",
    "\n",
    "    st.markdown(\"\"\"#### Three different approaches were used in this project:\n",
    "\\n1-TensorFlow\n",
    "\\n2-PyTorch\n",
    "\\n3-General Architecture of the Learning Algorithm\n",
    "\\n**For the third approach**, the focus was solely on the method. This approach did not yield favorable results, however, there are ways to improve this model. Updates will be made in the near future.\"\"\")\n",
    "\n",
    "with tab2:\n",
    "    def download_file_from_google_drive(id, destination):\n",
    "        URL = \"https://drive.google.com/uc?id=\" + id\n",
    "        response = requests.get(URL)\n",
    "        with open(destination, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "    class MyModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(MyModel, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "            self.fc1 = nn.Linear(64 * 56 * 56, 128)  # Adjust based on your input image size\n",
    "            self.fc2 = nn.Linear(128, 10)  # Assuming 10 classes\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(torch.relu(self.conv1(x)))\n",
    "            x = self.pool(torch.relu(self.conv2(x)))\n",
    "            x = x.view(-1, 64 * 56 * 56)  # Flatten the tensor\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    model_torch = MyModel()\n",
    "    model_torch.load_state_dict(torch.load('28_EfficientNet_97.pth'), strict=False)\n",
    "\n",
    "    with st.spinner('Loading Logistic Regression model'):\n",
    "        # File uploader for the Logistic Regression model\n",
    "        model_id = \"1hz-vGWfZOQa1EjtKq_6965VNhRg4HqaT?usp=sharing\"\n",
    "        download_file_from_google_drive(model_id, \"model_nn.pkl\")\n",
    "        Log_model = jb.load('model_nn.pkl')\n",
    "        st.write(\"Logistic Regression Model Loaded Successfully!\")\n",
    "\n",
    "    classes_name = jb.load('classes_name.pkl')\n",
    "\n",
    "    with st.spinner('Loading TensorFlow model (VGG16)'):\n",
    "        # File uploader for the TensorFlow model\n",
    "        model_id = \"1hz-vGWfZOQa1EjtKq_6965VNhRg4HqaT?usp=sharing\"\n",
    "        download_file_from_google_drive(model_id, '28_VGG16_88.h5')\n",
    "        tensor_model = tf.keras.models.load_model('28_VGG16_88.h5')\n",
    "        st.write(\"TensorFlow Model Loaded Successfully!\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4, 0.4, 0.4], [0.3, 0.3, 0.3])\n",
    "    ])\n",
    "\n",
    "    class StreamlitImageDataset(Dataset):\n",
    "        def __init__(self, uploaded_files, transform=None):\n",
    "            self.uploaded_files = uploaded_files\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.uploaded_files)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = Image.open(self.uploaded_files[idx]).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "\n",
    "    def predict_with_torch(model, dataloader):\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for img_tensor in dataloader:\n",
    "                outputs = model(img_tensor)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                predictions.append(preds.item())\n",
    "        return predictions\n",
    "\n",
    "    def softmax(z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=0, keepdims=True))\n",
    "        return exp_z / np.sum(exp_z, axis=0, keepdims=True)\n",
    "\n",
    "    def preprocess_image_for_nn(image):\n",
    "        img_rescaled = tf.image.resize(image, [224, 224])\n",
    "        img_rescaled = img_rescaled / 255.0\n",
    "        img_rescaled = img_rescaled.numpy()\n",
    "        img_flattened = img_rescaled.flatten().reshape(-1, 1)\n",
    "        return img_flattened\n",
    "\n",
    "    def predict_with_nn(model, image):\n",
    "        w = model['w']\n",
    "        b = model['b']\n",
    "        img_flattened = preprocess_image_for_nn(image)\n",
    "        A = softmax(np.dot(w.T, img_flattened) + b)\n",
    "        Y_prediction = np.argmax(A, axis=0)\n",
    "        return Y_prediction\n",
    "\n",
    "    def rescale(image):\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image /= 255.0\n",
    "        return tf.image.resize(image, [224, 224])\n",
    "\n",
    "    def decode_image(uploaded_file):\n",
    "        content = uploaded_file.read()\n",
    "        img = tf.image.decode_jpeg(content, channels=3)\n",
    "        img = rescale(img)\n",
    "        img = tf.expand_dims(img, axis=0)  # Add batch dimension\n",
    "        return img\n",
    "\n",
    "    uploaded_images = st.file_uploader(\"Choose a file\", type=[\"jpg\", \"jpeg\", \"png\"], accept_multiple_files=True)\n",
    "    col1, col2, col3 = st.columns([1, 1, 1])\n",
    "\n",
    "    with col1:\n",
    "        torch_prediction = st.button('Predict With Torch Model (Accuracy 97%)')\n",
    "    with col2:\n",
    "        nn_prediction = st.button('Predict With Logistic Regression Model')\n",
    "    with col3:\n",
    "        tensor_prediction = st.button('Predict With VGG16 tf (Accuracy 88%)')\n",
    "\n",
    "    if torch_prediction:\n",
    "        if uploaded_images:\n",
    "            dataset = StreamlitImageDataset(uploaded_files=uploaded_images, transform=transform)\n",
    "            dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "            predictions = predict_with_torch(model_torch, dataloader)\n",
    "            for idx, (prediction, file) in enumerate(zip(predictions, uploaded_images)):\n",
    "                st.image(file, caption=f'Predicted class: {classes_name[prediction]}', use_column_width=True)\n",
    "        else:\n",
    "            st.warning('No images were uploaded')\n",
    "\n",
    "    if nn_prediction:\n",
    "        if uploaded_images:\n",
    "            for image in uploaded_images:\n",
    "                content = image.read()\n",
    "                img = tf.image.decode_jpeg(content, channels=3)\n",
    "                prediction = predict_with_nn(Log_model, img)\n",
    "                st.image(image, caption=f'Predicted class: {classes_name[prediction[0]]}', use_column_width=True)\n",
    "        else:\n",
    "            st.warning('No images were uploaded')\n",
    "\n",
    "    if tensor_prediction:\n",
    "        if uploaded_images:\n",
    "            for image in uploaded_images:\n",
    "                img = decode_image(image)\n",
    "                prediction = tensor_model.predict(img)[0]  # No need for [0][0]\n",
    "                predicted_class = np.argmax(prediction)  # Get the index of the highest probability\n",
    "                st.image(image, caption=f'Predicted class: {classes_name[predicted_class]}', use_column_width=True)\n",
    "        else:\n",
    "            st.warning('No images were uploaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56119f-d442-40f2-b676-17d4fd0958a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40951b3-ac39-4b21-ae43-8516ded9b610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e833aab5-fed3-4ea0-9bc9-ce092a47af6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
